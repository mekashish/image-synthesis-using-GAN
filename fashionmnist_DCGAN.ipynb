{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMbf88CTqPbIwLuNjFj/RG7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"e5xLs9VMhu_i"},"outputs":[],"source":["\n","from keras.datasets import fashion_mnist\n","from keras.layers import *\n","from keras.models import Sequential,Model\n","\n","import numpy as np\n","import matplotlib.pyplot as plt \n","\n","# import matplotlib.pyplot as plt \n","\n","import math\n","\n","print(\"imported \")\n","LeakyReLU\n","print(3)\n"]},{"cell_type":"code","source":["from keras.layers import ELU, PReLU, LeakyReLU\n","from keras.optimizers import Adam\n","# from keras.layers.advanced_activations import LeakyReLU"],"metadata":{"id":"fbhd3PTwlSMZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install keras.layers.advanced_activations\n"],"metadata":{"id":"v8j_CJsdjJ5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#load dataset\n","(X_Train, _), (_, _) = fashion_mnist.load_data()"],"metadata":{"id":"hfUu3taHiuPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_Train.shape)"],"metadata":{"id":"VrEPRBq8jtAe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","plt.imshow(X_Train[18], cmap = 'gray')"],"metadata":{"id":"AXe6zYR_kFcU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","X_Train = X_Train.reshape((*X_Train.shape,1)) \n","X_Train = (X_Train.astype('float32')-127.5)/127.5\n","\n","print(np.min(X_Train))\n","print(np.max(X_Train))"],"metadata":{"id":"F5YrWli_kQRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TOTAL_EPOCHS = 50 \n","BATCH_SIZE = 256\n","NO_OF_BATCHES = int(X_Train.shape[0]/BATCH_SIZE)\n","HALF_BATCH =128\n","\n","NOISE_DIM = 100\n","adam = Adam(lr = 2e-4 , beta_1= 0.5)"],"metadata":{"id":"Zc4v41LrmbI2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define generator \n","\n","generator = Sequential()\n","\n","generator.add(Dense(7*7*128, input_shape = (NOISE_DIM,)))\n","generator.add(Reshape((7,7,128)))\n","generator.add(LeakyReLU(0.2))\n","generator.add(BatchNormalization())\n","\n","#double activation size 14 14 64 \n","\n","generator.add(UpSampling2D())\n","generator.add(Conv2D(64,kernel_size = (5,5), padding= 'same'))\n","generator.add(LeakyReLU(0.2))\n","generator.add(BatchNormalization())\n","\n","#double activation size 28 28 1 \n","\n","generator.add(UpSampling2D())\n","generator.add(Conv2D(1,kernel_size = (5,5), padding= 'same', activation= 'tanh'))\n","\n","\n","\n","generator.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n","generator.summary()\n","\n","\n","# define disc\n","\n"],"metadata":{"id":"Nw0k_rtwydsb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define disc\n","\n","\n","discriminator = Sequential()\n","discriminator.add(Conv2D(64,(5,5),strides=(2,2), padding  =  'same', input_shape=(28,28,1)))\n","discriminator.add(LeakyReLU(0.2))\n","\n","#next conv layer\n","discriminator.add(Conv2D(128,(5,5),strides=(2,2), padding  =  'same'))\n","discriminator.add(LeakyReLU(0.2))\n","\n","#flatten \n","\n","discriminator.add(Flatten())\n","\n","discriminator.add(Dense(1,activation = 'sigmoid'))\n","\n","discriminator.compile(loss= 'binary_crossentropy',optimizer = adam)\n","discriminator.summary()\n","\n","\n"],"metadata":{"id":"ce8gGORc1ELb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["discriminator.trainable = False\n","\n","gan_input = Input(shape = (NOISE_DIM,))\n","generated_img = generator(gan_input)\n","\n","gan_output = discriminator(generated_img)\n","#functional api\n","\n","model = Model(gan_input,gan_output)\n","model.compile(loss = 'binary_crossentropy', optimizer = adam)\n"],"metadata":{"id":"1C5FCEZl3GNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","def save_imgs(epoch, samples=100):\n","  noise  = np.random.normal(0,1,size = (samples , NOISE_DIM))\n","  generated_imgs = generator.predict(noise)\n","  generated_imgs = generated_imgs.reshape(samples, 28 , 28)\n","  \n","  plt.figure(figsize = (10,10))\n","\n","  for i in range(samples):\n","    plt.subplot(10,10,i+1)\n","    plt.imshow(generated_imgs[i], interpolation =  'nearest', cmap = 'gray')\n","    plt.axis(\"off\")\n","\n","  plt.tight_layout()\n","  plt.savefig('images/gan_output_epoch_{0}.png'.format(epoch+1))\n","  plt.show()\n","   \n"],"metadata":{"id":"-SpcktqiozNS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9DAxL6-_wCzc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls\n"],"metadata":{"id":"KOFqPDiN5Bo4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Training loop\n"],"metadata":{"id":"JiMsvsuLpXbw"}},{"cell_type":"code","source":["\n","\n","d_losses= []\n","g_losses=[]\n","for epoch in range(TOTAL_EPOCHS):\n","    epoch_d_loss = 0\n","    epoch_g_loss = 0\n","\n","    #MINI Batch SGD\n","    for step in range(NO_OF_BATCHES):\n","      \n","      # step-1 Disc\n","\n","      idx = np.random.randint(0, X_Train.shape[0] , HALF_BATCH)\n","      real_imgs   =  X_Train[idx]\n","\n","      noise = np.random.normal(0,1,size = (HALF_BATCH, NOISE_DIM))\n","\n","      fake_imgs = generator.predict(noise)\n","\n","                                    \n","      real_y = np.ones((HALF_BATCH,1))*0.9\n","      fake_y = np.zeros((HALF_BATCH,1))\n","\n","      #train our disc\n","\n","      d_loss_real = discriminator.train_on_batch(real_imgs, real_y)\n","      d_loss_fake = discriminator.train_on_batch(fake_imgs, fake_y)\n","      d_loss = 0.5*d_loss_real + 0.5*d_loss_fake\n","\n","      epoch_d_loss +=  d_loss\n","\n","\n","      #train generator \n","      noise  = np.random.normal(0,1,size = (BATCH_SIZE, NOISE_DIM))\n","\n","      ground_truth_y = np.ones((BATCH_SIZE,1))\n","\n","      g_loss = model.train_on_batch(noise,ground_truth_y)\n","\n","      epoch_g_loss += g_loss\n","\n","    print(\"epoch %d Disc loss %.4f Generator loss %.4f\" %((epoch+1 ), epoch_d_loss/NO_OF_BATCHES, epoch_g_loss/NO_OF_BATCHES))\n","    d_losses.append(epoch_d_loss/NO_OF_BATCHES)                             \n","    g_losses.append(epoch_g_loss/NO_OF_BATCHES)                             \n","\n","    if ( epoch+1) %5 == 0 :\n","      generator.save('model/gan_generator_{0}.h5'.format(epoch+1))\n","      save_imgs(epoch)\n","    \n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"AnMiurmMpa8K"},"execution_count":null,"outputs":[]}]}